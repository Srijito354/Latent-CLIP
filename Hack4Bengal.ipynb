{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import ImageFolder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "\n",
    "class ImageEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ImageEncoder, self).__init__()\n",
    "\n",
    "        self.embedding_dim = 16\n",
    "\n",
    "        # Downscaling layers for Q, K, V\n",
    "        self.w_q = nn.Linear(16, 2)\n",
    "        self.w_k = nn.Linear(16, 2)\n",
    "        self.w_v = nn.Linear(16, 2)\n",
    "\n",
    "        # Upscaling back to embedding dim\n",
    "        self.latent_upscale = nn.Linear(2, 16)\n",
    "\n",
    "        # Layer norm\n",
    "        self.layer_norm = nn.LayerNorm(16)\n",
    "\n",
    "        # Feedforward block\n",
    "        self.feed_fwd = nn.Sequential(\n",
    "            nn.Linear(16, 16),\n",
    "            nn.Linear(16, 16),\n",
    "            nn.Linear(16, 16)\n",
    "        )\n",
    "\n",
    "        # Final projection\n",
    "        self.output_proj = nn.Linear(16, 16)\n",
    "\n",
    "    def forward(self, x):\n",
    "        Q = self.w_q(x)\n",
    "        K = self.w_k(x)\n",
    "        V = self.w_v(x)\n",
    "\n",
    "        attention_scores = torch.matmul(Q, K.transpose(-2, -1)) / (self.embedding_dim ** 0.5)\n",
    "        attention_weights = F.softmax(attention_scores, dim=-1)\n",
    "        context = torch.matmul(attention_weights, V)\n",
    "\n",
    "        context = self.latent_upscale(context)\n",
    "\n",
    "        # Residual + Norm\n",
    "        x = self.layer_norm(context + x)\n",
    "\n",
    "        # Feedforward + Norm\n",
    "        ff_out = self.feed_fwd(x)\n",
    "        out = self.layer_norm(ff_out + x)\n",
    "\n",
    "        # Final linear (optional)\n",
    "        return self.output_proj(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 196, 16])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "img = Image.open('/home/lcamk2/idiot_programmer/kitchen-countertops-options.jpg')\n",
    "\n",
    "img = transform(img)\n",
    "\n",
    "layer = nn.Conv2d(in_channels = 3, out_channels = 16, kernel_size = 16, stride = 16)\n",
    "\n",
    "img = layer(img)\n",
    "img = img.unsqueeze(0)       \n",
    "img = img.permute(0, 2, 3, 1)\n",
    "img = img.view(1, 196, 16) \n",
    "\n",
    "pos_mat = nn.Parameter(torch.randn(1, 196, 16))\n",
    "x = img + pos_mat\n",
    "\n",
    "image_embeddings = ImageEncoder()\n",
    "encoded_img = image_embeddings(x)\n",
    "encoded_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embedding_gen(sentence):\n",
    "    global words\n",
    "    words = sentence.lower().split()\n",
    "    global word_idx\n",
    "    word_idx = {word: idx for idx, word in enumerate(words)}\n",
    "    global embedding_dim\n",
    "    embedding_dim = 16\n",
    "    global vocab_size\n",
    "    global idx_only\n",
    "    idx_only = [i for i in range(len(word_idx))]\n",
    "    vocab_size = len(word_idx)\n",
    "    embeddings = nn.Embedding(num_embeddings=vocab_size, embedding_dim=embedding_dim)\n",
    "    input_tensor = torch.LongTensor(idx_only)\n",
    "    input_embeddings = embeddings(input_tensor)\n",
    "    return input_embeddings\n",
    "\n",
    "def positional_encodings(sequence_length, embedding_size):\n",
    "    pe = torch.zeros(sequence_length, embedding_size)\n",
    "    pos_encode = 0\n",
    "    for pos in range(len(word_idx)):\n",
    "        em_dim = embedding_dim\n",
    "        for i in range(em_dim):\n",
    "            if i%2 == 0:\n",
    "                emma = torch.sin(torch.tensor(pos/(10000**((2*i)/embedding_dim))))\n",
    "            else:\n",
    "                emma = torch.cos(torch.tensor(pos/(10000**(((2*i)+1)/embedding_dim))))\n",
    "            pe[pos][i] = emma\n",
    "            #pe[pos][i+1] = emma2\n",
    "    return pe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "softmax = nn.Softmax(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TextEncoder, self).__init__()\n",
    "\n",
    "        self.embedding_dim = 16\n",
    "\n",
    "        self.w_q = nn.Linear(16, 2)\n",
    "        self.w_k = nn.Linear(16, 2)\n",
    "        self.w_v = nn.Linear(16, 2)\n",
    "\n",
    "        self.latent_upscale = nn.Linear(2, 16)\n",
    "        self.layer_norm = nn.LayerNorm(16)\n",
    "\n",
    "        self.feed_fwd = nn.Sequential(\n",
    "            nn.Linear(16, 16),\n",
    "            nn.Linear(16, 16),\n",
    "            nn.Linear(16, 16)\n",
    "        )\n",
    "\n",
    "        self.output_proj = nn.Linear(16, 16)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        Q = self.w_q(x)\n",
    "        K = self.w_k(x)\n",
    "        V = self.w_k(x)\n",
    "\n",
    "        attention_scores = torch.matmul(Q, K.transpose(-2, -1)) / (self.embedding_dim ** 0.5)\n",
    "        attention_weights = F.softmax(attention_scores, dim=-1)\n",
    "        context = torch.matmul(attention_weights, V)\n",
    "\n",
    "        context = self.latent_upscale(context)\n",
    "\n",
    "        # Residual + Norm\n",
    "        x = self.layer_norm(context + x)\n",
    "\n",
    "        # Feedforward + Norm\n",
    "        ff_out = self.feed_fwd(x)\n",
    "        out = self.layer_norm(ff_out + x)\n",
    "\n",
    "        # Final linear (optional)\n",
    "        return self.output_proj(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2, 16])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_embeddings = embedding_gen(\"Joy Maa!\")\n",
    "pe = positional_encodings(vocab_size, embedding_dim)\n",
    "\n",
    "y = input_embeddings + pe\n",
    "\n",
    "text_encoder = TextEncoder()\n",
    "y = y.unsqueeze(0)\n",
    "encoded_text = text_encoder(y)\n",
    "encoded_text.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "class CLIPMini(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CLIPMini, self).__init__()\n",
    "        self.image_encoder = ImageEncoder()\n",
    "        self.text_encoder = TextEncoder()\n",
    "\n",
    "    def forward(self, image_patches, text_tokens):\n",
    "        img_embs = self.image_encoder(image_patches)  # [B, 196, 16]\n",
    "        txt_embs = self.text_encoder(text_tokens) # [B, seq_len, 16]\n",
    "\n",
    "        # Pool\n",
    "        img_vec = torch.mean(img_embs, dim=1)      # [B, 16]\n",
    "        txt_vec = txt_embs[:, 0, :]                # [B, 16] - CLS\n",
    "\n",
    "        # Normalize\n",
    "        img_vec = F.normalize(img_vec, dim=-1)\n",
    "        txt_vec = F.normalize(txt_vec, dim=-1)\n",
    "\n",
    "        return img_vec, txt_vec\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CLIPMini(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CLIPMini, self).__init__()\n",
    "        self.image_encoder = ImageEncoder()\n",
    "        self.text_encoder = TextEncoder()\n",
    "\n",
    "    def forward(self, image_patches, text_tokens):\n",
    "\n",
    "        # Let's assume: image_patches: [B, 196, 16]\n",
    "        cls_token_img = nn.Parameter(torch.randn(1, 1, 16)).to(image_patches)\n",
    "        cls_token_img = cls_token_img.expand(image_patches.size(0), -1, -1)  # [B, 1, 16]\n",
    "\n",
    "        img_input = torch.cat([cls_token_img, image_patches], dim=1)  # [B, 197, 16]\n",
    "        img_embs = self.image_encoder(img_input)  # Encoder will attend to [CLS]\n",
    "\n",
    "        cls_token_txt = nn.Parameter(torch.randn(1, 1, 16)).to(text_tokens.device)\n",
    "        cls_token_txt = cls_token_txt.expand(text_tokens.size(0), -1, -1)  # [B, 1, 16]\n",
    "\n",
    "        txt_input = torch.cat([cls_token_txt, text_tokens], dim=1)  # [B, seq_len+1, 16]\n",
    "        txt_embs = self.text_encoder(txt_input)\n",
    "\n",
    "        '''\n",
    "        img_embs = self.image_encoder(image_patches)  # [B, 196, 16]\n",
    "        txt_embs = self.text_encoder(text_tokens) # [B, seq_len, 16]\n",
    "        '''\n",
    "\n",
    "        # Pool\n",
    "        #img_vec = torch.mean(img_embs, dim=1)      # [B, 16]\n",
    "        img_vec = img_embs[:, 0, :]                # [B, 16] with CLS\n",
    "        txt_vec = txt_embs[:, 0, :]                # [B, 16] with CLS\n",
    "\n",
    "        # Normalize\n",
    "        img_vec = F.normalize(img_vec, dim=-1)\n",
    "        txt_vec = F.normalize(txt_vec, dim=-1)\n",
    "\n",
    "        return img_vec, txt_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CLIPMini()\n",
    "i_vec, t_vec = model(encoded_img, encoded_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Define a transform for the images\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# Load the JSON\n",
    "with open('data/easy-VQA/easy_vqa/data/train/questions.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "image_paths = []\n",
    "questions = []\n",
    "answers = []\n",
    "\n",
    "for item in data:\n",
    "    img_path = f\"data/easy-VQA/easy_vqa/data/train/images/{item[2]}.png\"\n",
    "    question = item[0]\n",
    "    answer = item[1]\n",
    "\n",
    "    image_paths.append(img_path)\n",
    "    questions.append(question)\n",
    "    answers.append(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "class EasyVQADataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, image_paths, questions, answers, transform, text_encoder):\n",
    "        self.image_paths = image_paths\n",
    "        self.questions = questions\n",
    "        self.answers = answers\n",
    "        self.transform = transform\n",
    "        self.text_encoder = text_encoder\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.questions)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = Image.open(self.image_paths[idx]).convert(\"RGB\")\n",
    "        image = self.transform(image)\n",
    "\n",
    "        question = self.questions[idx]\n",
    "        input_em = embedding_gen(question)\n",
    "        pe = positional_encodings(vocab_size, embedding_dim)\n",
    "        question_embedding = input_em + pe\n",
    "\n",
    "        answer = self.answers[idx]\n",
    "        input_ans = embedding_gen(answer)\n",
    "        pe = positional_encodings(vocab_size, embedding_dim)\n",
    "        answer_embedding = input_ans + pe\n",
    "\n",
    "        return image, question_embedding, answer_embedding\n",
    "\n",
    "def collate_fn(batch):\n",
    "    images, questions, answers = zip(*batch)\n",
    "    #images = list(images)  # [B, 224, 224]\n",
    "\n",
    "    # Pad questions to same length\n",
    "    padded_images = pad_sequence(images, batch_first=True)\n",
    "    padded_questions = pad_sequence(questions, batch_first=True)  # [B, max_seq_len, 16]\n",
    "    padded_answers = pad_sequence(answers, batch_first=True)  # [B, max_seq_len, 16]\n",
    "\n",
    "    return padded_images, padded_questions, padded_answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = EasyVQADataset(image_paths, questions, answers, transform, text_encoder=None)\n",
    "batch_size = 8\n",
    "loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[0.9765, 0.9765, 0.9765,  ..., 0.9765, 0.9765, 0.9765],\n",
      "          [0.9765, 0.9765, 0.9765,  ..., 0.9765, 0.9765, 0.9765],\n",
      "          [0.9765, 0.9765, 0.9765,  ..., 0.9765, 0.9765, 0.9765],\n",
      "          ...,\n",
      "          [0.9765, 0.9765, 0.9765,  ..., 0.9765, 0.9765, 0.9765],\n",
      "          [0.9765, 0.9765, 0.9765,  ..., 0.9765, 0.9765, 0.9765],\n",
      "          [0.9765, 0.9765, 0.9765,  ..., 0.9765, 0.9765, 0.9765]],\n",
      "\n",
      "         [[0.9176, 0.9176, 0.9176,  ..., 0.9176, 0.9176, 0.9176],\n",
      "          [0.9176, 0.9176, 0.9176,  ..., 0.9176, 0.9176, 0.9176],\n",
      "          [0.9176, 0.9176, 0.9176,  ..., 0.9176, 0.9176, 0.9176],\n",
      "          ...,\n",
      "          [0.9176, 0.9176, 0.9176,  ..., 0.9176, 0.9176, 0.9176],\n",
      "          [0.9176, 0.9176, 0.9176,  ..., 0.9176, 0.9176, 0.9176],\n",
      "          [0.9176, 0.9176, 0.9176,  ..., 0.9176, 0.9176, 0.9176]],\n",
      "\n",
      "         [[0.9804, 0.9804, 0.9804,  ..., 0.9804, 0.9804, 0.9804],\n",
      "          [0.9804, 0.9804, 0.9804,  ..., 0.9804, 0.9804, 0.9804],\n",
      "          [0.9804, 0.9804, 0.9804,  ..., 0.9804, 0.9804, 0.9804],\n",
      "          ...,\n",
      "          [0.9804, 0.9804, 0.9804,  ..., 0.9804, 0.9804, 0.9804],\n",
      "          [0.9804, 0.9804, 0.9804,  ..., 0.9804, 0.9804, 0.9804],\n",
      "          [0.9804, 0.9804, 0.9804,  ..., 0.9804, 0.9804, 0.9804]]],\n",
      "\n",
      "\n",
      "        [[[0.9529, 0.9529, 0.9529,  ..., 0.9529, 0.9529, 0.9529],\n",
      "          [0.9529, 0.9529, 0.9529,  ..., 0.9529, 0.9529, 0.9529],\n",
      "          [0.9529, 0.9529, 0.9529,  ..., 0.9529, 0.9529, 0.9529],\n",
      "          ...,\n",
      "          [0.9529, 0.9529, 0.9529,  ..., 0.9529, 0.9529, 0.9529],\n",
      "          [0.9529, 0.9529, 0.9529,  ..., 0.9529, 0.9529, 0.9529],\n",
      "          [0.9529, 0.9529, 0.9529,  ..., 0.9529, 0.9529, 0.9529]],\n",
      "\n",
      "         [[0.9333, 0.9333, 0.9333,  ..., 0.9333, 0.9333, 0.9333],\n",
      "          [0.9333, 0.9333, 0.9333,  ..., 0.9333, 0.9333, 0.9333],\n",
      "          [0.9333, 0.9333, 0.9333,  ..., 0.9333, 0.9333, 0.9333],\n",
      "          ...,\n",
      "          [0.9333, 0.9333, 0.9333,  ..., 0.9333, 0.9333, 0.9333],\n",
      "          [0.9333, 0.9333, 0.9333,  ..., 0.9333, 0.9333, 0.9333],\n",
      "          [0.9333, 0.9333, 0.9333,  ..., 0.9333, 0.9333, 0.9333]],\n",
      "\n",
      "         [[0.9020, 0.9020, 0.9020,  ..., 0.9020, 0.9020, 0.9020],\n",
      "          [0.9020, 0.9020, 0.9020,  ..., 0.9020, 0.9020, 0.9020],\n",
      "          [0.9020, 0.9020, 0.9020,  ..., 0.9020, 0.9020, 0.9020],\n",
      "          ...,\n",
      "          [0.9020, 0.9020, 0.9020,  ..., 0.9020, 0.9020, 0.9020],\n",
      "          [0.9020, 0.9020, 0.9020,  ..., 0.9020, 0.9020, 0.9020],\n",
      "          [0.9020, 0.9020, 0.9020,  ..., 0.9020, 0.9020, 0.9020]]],\n",
      "\n",
      "\n",
      "        [[[0.9686, 0.9686, 0.9686,  ..., 0.9686, 0.9686, 0.9686],\n",
      "          [0.9686, 0.9686, 0.9686,  ..., 0.9686, 0.9686, 0.9686],\n",
      "          [0.9686, 0.9686, 0.9686,  ..., 0.9686, 0.9686, 0.9686],\n",
      "          ...,\n",
      "          [0.9686, 0.9686, 0.9686,  ..., 0.9686, 0.9686, 0.9686],\n",
      "          [0.9686, 0.9686, 0.9686,  ..., 0.9686, 0.9686, 0.9686],\n",
      "          [0.9686, 0.9686, 0.9686,  ..., 0.9686, 0.9686, 0.9686]],\n",
      "\n",
      "         [[0.9451, 0.9451, 0.9451,  ..., 0.9451, 0.9451, 0.9451],\n",
      "          [0.9451, 0.9451, 0.9451,  ..., 0.9451, 0.9451, 0.9451],\n",
      "          [0.9451, 0.9451, 0.9451,  ..., 0.9451, 0.9451, 0.9451],\n",
      "          ...,\n",
      "          [0.9451, 0.9451, 0.9451,  ..., 0.9451, 0.9451, 0.9451],\n",
      "          [0.9451, 0.9451, 0.9451,  ..., 0.9451, 0.9451, 0.9451],\n",
      "          [0.9451, 0.9451, 0.9451,  ..., 0.9451, 0.9451, 0.9451]],\n",
      "\n",
      "         [[0.9882, 0.9882, 0.9882,  ..., 0.9882, 0.9882, 0.9882],\n",
      "          [0.9882, 0.9882, 0.9882,  ..., 0.9882, 0.9882, 0.9882],\n",
      "          [0.9882, 0.9882, 0.9882,  ..., 0.9882, 0.9882, 0.9882],\n",
      "          ...,\n",
      "          [0.9882, 0.9882, 0.9882,  ..., 0.9882, 0.9882, 0.9882],\n",
      "          [0.9882, 0.9882, 0.9882,  ..., 0.9882, 0.9882, 0.9882],\n",
      "          [0.9882, 0.9882, 0.9882,  ..., 0.9882, 0.9882, 0.9882]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "          ...,\n",
      "          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000]],\n",
      "\n",
      "         [[0.9961, 0.9961, 0.9961,  ..., 0.9961, 0.9961, 0.9961],\n",
      "          [0.9961, 0.9961, 0.9961,  ..., 0.9961, 0.9961, 0.9961],\n",
      "          [0.9961, 0.9961, 0.9961,  ..., 0.9961, 0.9961, 0.9961],\n",
      "          ...,\n",
      "          [0.9961, 0.9961, 0.9961,  ..., 0.9961, 0.9961, 0.9961],\n",
      "          [0.9961, 0.9961, 0.9961,  ..., 0.9961, 0.9961, 0.9961],\n",
      "          [0.9961, 0.9961, 0.9961,  ..., 0.9961, 0.9961, 0.9961]],\n",
      "\n",
      "         [[0.9373, 0.9373, 0.9373,  ..., 0.9373, 0.9373, 0.9373],\n",
      "          [0.9373, 0.9373, 0.9373,  ..., 0.9373, 0.9373, 0.9373],\n",
      "          [0.9373, 0.9373, 0.9373,  ..., 0.9373, 0.9373, 0.9373],\n",
      "          ...,\n",
      "          [0.9373, 0.9373, 0.9373,  ..., 0.9373, 0.9373, 0.9373],\n",
      "          [0.9373, 0.9373, 0.9373,  ..., 0.9373, 0.9373, 0.9373],\n",
      "          [0.9373, 0.9373, 0.9373,  ..., 0.9373, 0.9373, 0.9373]]],\n",
      "\n",
      "\n",
      "        [[[0.9098, 0.9098, 0.9098,  ..., 0.9098, 0.9098, 0.9098],\n",
      "          [0.9098, 0.9098, 0.9098,  ..., 0.9098, 0.9098, 0.9098],\n",
      "          [0.9098, 0.9098, 0.9098,  ..., 0.9098, 0.9098, 0.9098],\n",
      "          ...,\n",
      "          [0.9098, 0.9098, 0.9098,  ..., 0.9098, 0.9098, 0.9098],\n",
      "          [0.9098, 0.9098, 0.9098,  ..., 0.9098, 0.9098, 0.9098],\n",
      "          [0.9098, 0.9098, 0.9098,  ..., 0.9098, 0.9098, 0.9098]],\n",
      "\n",
      "         [[0.9059, 0.9059, 0.9059,  ..., 0.9059, 0.9059, 0.9059],\n",
      "          [0.9059, 0.9059, 0.9059,  ..., 0.9059, 0.9059, 0.9059],\n",
      "          [0.9059, 0.9059, 0.9059,  ..., 0.9059, 0.9059, 0.9059],\n",
      "          ...,\n",
      "          [0.9059, 0.9059, 0.9059,  ..., 0.9059, 0.9059, 0.9059],\n",
      "          [0.9059, 0.9059, 0.9059,  ..., 0.9059, 0.9059, 0.9059],\n",
      "          [0.9059, 0.9059, 0.9059,  ..., 0.9059, 0.9059, 0.9059]],\n",
      "\n",
      "         [[0.9725, 0.9725, 0.9725,  ..., 0.9725, 0.9725, 0.9725],\n",
      "          [0.9725, 0.9725, 0.9725,  ..., 0.9725, 0.9725, 0.9725],\n",
      "          [0.9725, 0.9725, 0.9725,  ..., 0.9725, 0.9725, 0.9725],\n",
      "          ...,\n",
      "          [0.9725, 0.9725, 0.9725,  ..., 0.9725, 0.9725, 0.9725],\n",
      "          [0.9725, 0.9725, 0.9725,  ..., 0.9725, 0.9725, 0.9725],\n",
      "          [0.9725, 0.9725, 0.9725,  ..., 0.9725, 0.9725, 0.9725]]],\n",
      "\n",
      "\n",
      "        [[[0.9176, 0.9176, 0.9176,  ..., 0.9176, 0.9176, 0.9176],\n",
      "          [0.9176, 0.9176, 0.9176,  ..., 0.9176, 0.9176, 0.9176],\n",
      "          [0.9176, 0.9176, 0.9176,  ..., 0.9176, 0.9176, 0.9176],\n",
      "          ...,\n",
      "          [0.9176, 0.9176, 0.9176,  ..., 0.9176, 0.9176, 0.9176],\n",
      "          [0.9176, 0.9176, 0.9176,  ..., 0.9176, 0.9176, 0.9176],\n",
      "          [0.9176, 0.9176, 0.9176,  ..., 0.9176, 0.9176, 0.9176]],\n",
      "\n",
      "         [[0.9176, 0.9176, 0.9176,  ..., 0.9176, 0.9176, 0.9176],\n",
      "          [0.9176, 0.9176, 0.9176,  ..., 0.9176, 0.9176, 0.9176],\n",
      "          [0.9176, 0.9176, 0.9176,  ..., 0.9176, 0.9176, 0.9176],\n",
      "          ...,\n",
      "          [0.9176, 0.9176, 0.9176,  ..., 0.9176, 0.9176, 0.9176],\n",
      "          [0.9176, 0.9176, 0.9176,  ..., 0.9176, 0.9176, 0.9176],\n",
      "          [0.9176, 0.9176, 0.9176,  ..., 0.9176, 0.9176, 0.9176]],\n",
      "\n",
      "         [[0.9216, 0.9216, 0.9216,  ..., 0.9216, 0.9216, 0.9216],\n",
      "          [0.9216, 0.9216, 0.9216,  ..., 0.9216, 0.9216, 0.9216],\n",
      "          [0.9216, 0.9216, 0.9216,  ..., 0.9216, 0.9216, 0.9216],\n",
      "          ...,\n",
      "          [0.9216, 0.9216, 0.9216,  ..., 0.9216, 0.9216, 0.9216],\n",
      "          [0.9216, 0.9216, 0.9216,  ..., 0.9216, 0.9216, 0.9216],\n",
      "          [0.9216, 0.9216, 0.9216,  ..., 0.9216, 0.9216, 0.9216]]]])\n",
      "tensor([[[-1.3640e+00,  1.2255e+00,  1.7365e+00,  1.0551e-01,  2.2564e-01,\n",
      "           1.3101e+00,  3.1528e-02,  1.9513e+00,  6.6698e-01,  1.2987e+00,\n",
      "           9.0084e-01,  7.9275e-01, -1.1914e+00,  1.7509e+00, -9.9870e-01,\n",
      "           1.8019e+00],\n",
      "         [-4.1855e-01,  2.9812e-01, -1.8532e-01,  9.9614e-01, -9.1635e-01,\n",
      "          -1.4537e+00, -2.5700e-01,  1.2957e+00,  7.2415e-01,  2.4867e-01,\n",
      "           5.4815e-01,  1.7769e+00, -8.7135e-01,  4.1220e-01, -1.2379e-01,\n",
      "          -3.5654e-02],\n",
      "         [ 1.5139e+00,  1.3378e-01,  9.6992e-02,  1.8094e+00,  3.1261e-01,\n",
      "           5.4047e-02,  3.0917e-01,  2.3657e+00,  3.3361e-01,  2.2756e+00,\n",
      "           5.2922e-01,  2.7984e+00,  2.4862e+00,  3.8473e-01, -7.4806e-01,\n",
      "           1.7331e+00],\n",
      "         [ 4.6000e-01,  2.7719e-01, -3.6141e-01,  2.4410e+00, -9.3540e-01,\n",
      "           1.5461e+00,  8.3596e-01,  5.3987e-01, -3.0002e-02,  2.3056e+00,\n",
      "           1.6800e-01,  1.5443e-01, -9.1055e-01, -1.5959e-01,  3.3633e-01,\n",
      "           1.9967e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "           0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "           0.0000e+00]],\n",
      "\n",
      "        [[-5.8698e-01,  5.1799e-01,  1.5612e-01,  9.5588e-01, -7.0129e-01,\n",
      "           1.7385e+00, -1.1679e+00,  2.6515e+00,  1.5169e+00,  7.5115e-01,\n",
      "          -8.1355e-01,  2.0307e+00,  9.4933e-01, -2.4522e-01,  1.4029e+00,\n",
      "          -4.1171e-01],\n",
      "         [ 1.2659e+00,  3.9413e-01,  1.9658e+00, -1.1319e-01,  1.5019e-01,\n",
      "           3.5035e+00,  9.9675e-01,  1.4504e+00, -9.5433e-01,  3.3630e+00,\n",
      "          -3.1719e-01,  1.4755e+00,  9.1159e-01,  6.7812e-01, -6.8182e-01,\n",
      "           1.4077e+00],\n",
      "         [ 1.8922e+00, -1.0251e-01, -8.2275e-01, -6.8994e-01, -6.7551e-01,\n",
      "           1.0290e+00, -1.7835e+00,  7.5874e-01,  3.1537e-01,  1.7913e+00,\n",
      "          -4.5639e-01,  8.3148e-01, -2.0827e+00,  1.4964e+00,  9.6213e-01,\n",
      "           7.5238e-01],\n",
      "         [-4.4330e-01,  8.6572e-01, -5.4174e-01,  4.7434e-01, -2.4003e-01,\n",
      "           1.3541e+00, -1.3813e+00, -2.8461e-01, -3.6818e-01,  2.6080e+00,\n",
      "          -1.0752e+00,  1.1174e-01,  2.7084e-02,  1.2852e+00, -4.5394e-01,\n",
      "           1.8954e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "           0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "           0.0000e+00]],\n",
      "\n",
      "        [[ 7.4452e-02,  9.2499e-01, -4.7466e-01,  1.8331e+00,  6.6219e-01,\n",
      "          -7.9152e-02,  6.6964e-02,  2.5201e+00, -1.1487e+00,  1.5185e+00,\n",
      "          -1.1615e+00,  2.9446e+00, -3.8134e-01, -4.1088e-01, -2.3505e+00,\n",
      "           1.2155e+00],\n",
      "         [-2.1868e+00,  4.0130e-01,  2.2542e+00, -2.7535e-01, -9.9742e-01,\n",
      "           1.1686e+00,  1.0872e+00,  2.7882e+00,  1.9487e-01, -1.0153e+00,\n",
      "          -1.6387e+00,  8.2791e-01, -3.2675e-01,  7.7721e-01,  1.0896e+00,\n",
      "           1.4400e+00],\n",
      "         [ 9.7015e-01,  1.2393e+00, -5.5476e-01,  1.4564e+00,  7.2619e-01,\n",
      "           2.2022e+00,  5.2272e-01,  2.7285e+00,  1.0793e+00,  1.5143e+00,\n",
      "          -6.4529e-01,  1.2919e+00,  2.2031e-01,  4.0514e-01,  9.1139e-01,\n",
      "           1.1089e-01],\n",
      "         [-1.2694e-01, -2.2639e+00,  1.4069e+00,  1.4865e+00,  1.5589e+00,\n",
      "           2.4389e+00,  5.5779e-01,  2.3741e+00, -5.3456e-01,  3.8887e-01,\n",
      "          -2.7666e-01,  2.3679e-01, -2.9412e+00,  6.1060e-01, -4.2410e-01,\n",
      "           7.7821e-01],\n",
      "         [-1.3063e-01,  3.1526e-01,  7.3088e-01,  2.6952e+00, -1.0094e-01,\n",
      "           1.2773e+00,  2.0139e+00,  1.7459e+00, -2.2367e+00,  1.6705e-01,\n",
      "          -5.5765e-01,  1.2224e+00,  4.3271e-01, -6.2791e-01,  9.3536e-01,\n",
      "           2.2404e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "           0.0000e+00]],\n",
      "\n",
      "        [[ 5.6261e-01,  1.1229e+00,  1.8955e+00, -3.2981e-01, -3.1766e-01,\n",
      "           1.3414e+00, -9.2938e-01,  1.9946e+00, -8.0228e-02,  1.6620e+00,\n",
      "          -1.4180e+00,  3.1086e+00,  1.0344e-01,  2.5555e+00,  4.8316e-01,\n",
      "          -1.4748e-01],\n",
      "         [-8.9325e-01,  4.5840e-01,  7.2951e-01,  1.4174e+00,  9.3811e-01,\n",
      "           1.5352e-02, -4.4053e-01,  2.2846e+00,  1.7639e+00,  2.5901e+00,\n",
      "          -2.2496e-01,  1.3094e+00,  9.5439e-01,  1.2041e+00,  2.3860e-01,\n",
      "           2.2444e+00],\n",
      "         [ 1.4977e+00,  6.0976e-01, -3.2720e-01,  1.2227e+00,  4.4519e-01,\n",
      "           1.5944e+00, -2.3305e+00,  1.8653e-01, -2.4163e-01,  3.6404e-01,\n",
      "           9.7361e-01,  7.8440e-01, -5.4414e-01,  1.1769e+00,  7.7227e-01,\n",
      "           6.5854e-01],\n",
      "         [-1.1928e+00,  9.4633e-01,  5.6565e-01, -3.1221e-01,  2.9483e-02,\n",
      "           6.2640e-01, -2.1360e+00, -7.1446e-02, -4.2636e-02,  2.5053e+00,\n",
      "          -1.7289e+00,  1.6546e+00, -1.6996e+00,  1.5330e+00, -1.5726e+00,\n",
      "           5.9596e-01],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "           0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "           0.0000e+00]],\n",
      "\n",
      "        [[-1.5158e+00, -2.0548e-01, -1.1297e+00,  1.0932e+00,  9.2787e-01,\n",
      "           2.9923e-01, -2.4154e-01, -4.6469e-01,  8.4951e-01,  2.8413e-01,\n",
      "          -4.7990e-01, -8.9489e-01,  8.1779e-01,  1.7128e+00, -2.3253e-01,\n",
      "           9.6342e-01],\n",
      "         [ 9.8160e-02,  1.8345e+00,  2.3467e-01,  2.6479e+00,  8.7936e-01,\n",
      "           7.8672e-01, -3.0460e-01,  1.4600e+00,  3.3408e-01,  2.6122e+00,\n",
      "          -1.9874e+00,  1.8457e+00,  4.6265e-01,  1.6299e+00, -1.6792e-01,\n",
      "           1.2021e+00],\n",
      "         [ 6.2272e-01,  2.6620e+00, -1.1375e+00,  2.8814e+00, -3.1391e-01,\n",
      "           1.1844e+00,  7.9160e-03,  8.8493e-01, -3.5416e-01,  4.0446e-01,\n",
      "           1.9261e+00,  8.6861e-02,  4.0224e-01,  9.2545e-01,  1.0487e+00,\n",
      "           9.6559e-01],\n",
      "         [-9.5644e-01,  2.5671e-01, -3.4486e-01,  1.8170e+00,  4.8548e-01,\n",
      "           1.1882e+00, -1.1674e+00,  1.8684e+00, -2.3234e-01,  5.9500e-01,\n",
      "          -1.3307e-01,  1.2574e-01, -1.7777e-02,  1.5705e+00,  7.2898e-01,\n",
      "           4.5195e-01],\n",
      "         [ 3.7184e-01, -1.2274e-01, -8.6326e-01,  1.1781e+00,  5.0491e-01,\n",
      "           2.3135e+00,  1.5361e-01,  6.0466e-01, -2.2760e+00,  1.4158e-01,\n",
      "          -3.3590e-01,  1.0041e+00,  4.1554e-01,  7.5371e-01, -1.6095e+00,\n",
      "          -3.7278e-03],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "           0.0000e+00]],\n",
      "\n",
      "        [[-2.0329e-01,  2.7362e+00,  3.9327e-01, -4.7623e-01,  3.4550e-01,\n",
      "           7.1140e-01, -4.6752e-01,  1.9932e+00,  1.3179e+00,  8.9625e-01,\n",
      "          -2.6962e-02,  2.4751e+00, -4.4923e-01, -1.5202e+00,  1.0349e+00,\n",
      "           2.0503e-01],\n",
      "         [ 1.0008e+00,  1.0088e+00,  8.0698e-01,  1.3578e+00, -3.5698e-01,\n",
      "           8.0779e-01, -1.2444e+00, -1.2997e-01,  1.1354e+00, -5.3582e-01,\n",
      "          -3.2868e-01,  9.0358e-01, -1.7166e+00,  9.4947e-01, -1.4548e+00,\n",
      "           2.6163e+00],\n",
      "         [ 1.1629e+00,  2.5302e+00,  1.0353e-01,  3.0826e+00,  1.2886e+00,\n",
      "          -1.5945e+00,  4.3471e-01,  2.0941e+00, -3.0549e-01,  1.4905e+00,\n",
      "          -4.4599e-01,  8.1340e-01, -8.3957e-01,  2.1900e+00, -1.6634e-01,\n",
      "           9.4465e-01],\n",
      "         [ 8.0712e-01,  4.7278e-01,  5.8518e-01,  1.8777e+00, -7.8323e-01,\n",
      "           2.7568e+00,  5.4646e-01, -9.2713e-01, -9.1423e-01,  2.7949e-01,\n",
      "          -6.2923e-01,  2.3484e+00,  1.2261e+00,  1.5702e+00,  3.9719e-01,\n",
      "          -9.2502e-02],\n",
      "         [ 2.3218e-01,  5.8288e-01,  6.4246e-01,  1.0897e+00, -1.8814e+00,\n",
      "           9.1372e-01, -6.7808e-01,  3.0480e-01,  5.3654e-01,  2.6653e-02,\n",
      "          -6.2936e-01,  1.2730e+00, -3.9488e-01,  1.4610e+00,  9.3302e-01,\n",
      "           2.6527e-01],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "           0.0000e+00]],\n",
      "\n",
      "        [[ 3.8316e-01,  3.0074e+00,  4.1118e-01,  4.9581e-01, -5.6948e-01,\n",
      "           2.0412e+00,  6.2849e-01,  2.5472e-01, -1.5395e+00,  4.7861e-01,\n",
      "           3.5068e-01,  1.5729e+00,  7.6036e-01,  1.3672e+00, -1.0506e+00,\n",
      "           1.1497e+00],\n",
      "         [ 7.0194e-01,  1.6341e-01,  6.3799e-01,  6.9964e-01, -9.8648e-02,\n",
      "          -1.1520e-01,  1.9625e-01,  1.2482e+00, -1.2851e+00,  3.4035e-01,\n",
      "           1.8953e+00,  1.4365e+00, -1.4144e+00,  3.1807e-01,  4.9834e-01,\n",
      "           1.5359e+00],\n",
      "         [ 1.1740e+00,  1.3256e+00,  7.9065e-01,  2.3827e+00, -3.1149e-01,\n",
      "          -3.5370e-02, -1.2242e+00,  4.4059e-01,  6.2536e-01,  2.0084e+00,\n",
      "          -1.5600e+00,  2.9829e-01,  1.0231e-02,  1.6766e+00, -4.6631e-02,\n",
      "          -2.8916e-01],\n",
      "         [ 4.3526e-01,  2.7083e+00, -1.4482e+00,  5.0610e-01, -1.0067e+00,\n",
      "           1.8707e+00,  3.4231e-01,  7.0854e-01,  5.2581e-02,  1.8883e+00,\n",
      "          -5.6505e-01,  2.7801e+00, -5.0329e-01,  2.5928e-01,  4.4547e-01,\n",
      "           1.4332e+00],\n",
      "         [-6.9571e-01,  8.3477e-01,  1.1614e+00,  1.0153e+00, -2.8632e-01,\n",
      "           1.3249e+00, -1.0010e+00,  1.9061e+00, -8.6319e-02,  1.7783e+00,\n",
      "           7.3020e-01,  2.0578e+00,  1.4920e-01, -1.1368e-01, -9.3911e-02,\n",
      "          -2.0837e+00],\n",
      "         [-1.3583e+00, -2.4837e+00,  8.3429e-01,  1.0751e+00,  4.3933e-01,\n",
      "           6.1299e-01,  9.8384e-01,  8.4885e-01,  1.7847e-01,  3.4681e-01,\n",
      "          -1.6995e+00,  1.6788e+00,  2.4834e-01, -5.6117e-01, -2.5703e-01,\n",
      "           1.1371e+00]],\n",
      "\n",
      "        [[-2.0022e-01,  1.1995e+00, -2.0664e-01,  1.3815e-01, -1.4078e+00,\n",
      "           1.0924e+00, -8.4311e-01,  1.4669e+00, -1.6383e+00,  6.8189e-01,\n",
      "           2.6762e+00,  1.5521e+00,  1.2015e+00, -1.3338e-01, -5.7722e-01,\n",
      "           1.3527e+00],\n",
      "         [ 1.2402e+00,  3.4878e-01,  8.9305e-01, -5.7115e-01,  1.7325e+00,\n",
      "          -5.8475e-01, -8.7979e-01, -8.0039e-01,  1.4604e-01,  2.1174e+00,\n",
      "           1.2173e+00,  2.1395e+00,  6.3855e-01,  3.0667e+00, -3.6040e-02,\n",
      "           1.0125e+00],\n",
      "         [ 1.2883e+00,  1.2557e+00,  5.6497e-01,  1.2090e+00, -1.1518e+00,\n",
      "          -7.7609e-01, -6.4496e-01, -4.3419e-01, -3.1270e-01,  4.0253e+00,\n",
      "          -3.1223e-01,  4.7666e-01,  1.7989e-01,  2.2461e+00, -1.2769e+00,\n",
      "           1.7730e+00],\n",
      "         [-2.6140e-01,  1.8390e-01,  1.3535e+00,  7.0491e-01, -1.2731e+00,\n",
      "           4.2619e-02, -1.8361e+00,  1.3191e+00, -1.7471e+00,  1.5093e+00,\n",
      "          -2.8587e-01,  5.8590e-01, -8.6033e-01,  1.4813e+00, -1.3031e+00,\n",
      "           2.0320e+00],\n",
      "         [-2.8923e+00,  4.7485e-01,  7.2010e-01,  2.0501e+00,  1.5768e+00,\n",
      "           7.7907e-01,  2.8655e-01,  6.7088e-01,  1.9064e+00, -3.2108e-01,\n",
      "           4.1557e-01,  1.1517e+00, -4.9720e-01,  2.9589e+00, -8.7469e-01,\n",
      "           1.6499e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "           0.0000e+00]]], grad_fn=<CopySlices>)\n",
      "tensor([[[-0.5540, -0.5598,  0.8247,  2.4291,  0.0568,  1.7572, -1.0746,\n",
      "           0.3213, -0.2367,  0.6655, -0.1277,  1.0495, -0.3233,  1.1258,\n",
      "           1.2617, -0.4828]],\n",
      "\n",
      "        [[-1.2502,  0.8501, -0.2765,  1.0521, -0.3276,  1.9704,  0.9464,\n",
      "           2.5979, -0.4441,  0.7888, -0.8045, -0.3361,  0.3125,  1.4650,\n",
      "           1.6030, -1.0255]],\n",
      "\n",
      "        [[ 0.9504,  0.7066, -0.0713,  0.9293,  0.4760,  0.9453, -0.4975,\n",
      "           0.3146,  0.3685,  0.2355, -0.1338,  2.2580,  0.9583, -0.2817,\n",
      "          -1.4726,  0.4196]],\n",
      "\n",
      "        [[ 0.7216,  1.1279,  0.9003,  0.2662,  0.0992, -1.4033, -0.0376,\n",
      "          -0.3399, -1.0074,  0.4497,  0.2398,  1.7856, -0.0134,  2.4436,\n",
      "           0.4036,  0.6485]],\n",
      "\n",
      "        [[-0.5041,  1.3613, -0.0321,  0.9830, -0.7009,  0.3739, -1.3901,\n",
      "           1.1622,  0.2789,  2.5203,  0.2197,  1.2522, -0.0954,  0.9829,\n",
      "          -0.7293,  1.3480]],\n",
      "\n",
      "        [[-0.9177,  2.3737, -0.8366, -0.2866,  1.6940,  0.6390, -0.9418,\n",
      "          -0.0152, -0.9757,  0.7474, -0.5023,  0.5385,  1.0819,  1.6278,\n",
      "          -1.2340,  1.9122]],\n",
      "\n",
      "        [[ 1.0857,  3.0792,  0.0941,  1.5627,  0.9190,  2.9212, -0.3832,\n",
      "          -0.0177, -0.4783, -0.3472, -0.6989,  1.4980,  1.2484,  2.5452,\n",
      "          -0.0405,  1.7041]],\n",
      "\n",
      "        [[-0.9336,  1.6971, -1.4387,  1.5226, -1.3370,  2.2672,  0.1470,\n",
      "           0.1246,  0.3714, -0.0490, -0.2859,  1.9626,  0.3958,  1.6571,\n",
      "           0.5838,  0.1805]]], grad_fn=<CopySlices>)\n"
     ]
    }
   ],
   "source": [
    "for imgs, qs, ans in loader:\n",
    "    print(imgs)  # [B, 3, 224, 224]\n",
    "    print(qs)          # List of strings\n",
    "    print(ans)         # List of strings\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 3, 224, 224])"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 16, 14, 14])"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_bed = layer(imgs)\n",
    "img_bed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 8])\n"
     ]
    }
   ],
   "source": [
    "layer = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=(16, 16), stride=16)\n",
    "#patches = embed(images).flatten(2).transpose(1, 2)\n",
    "\n",
    "pos_mat = nn.Parameter(torch.randn(batch_size, 196, 16))\n",
    "model = CLIPMini()\n",
    "\n",
    "for epoch in range(100):\n",
    "    for imgs, qs_em, ans_em in loader:\n",
    "        img_em = layer(imgs).flatten(2).transpose(1, 2)\n",
    "        #img_em = img_em.permute(0, 2, 1)\n",
    "        #img_em = img_em.view(batch_size, 196, 16)\n",
    "        img_pass = img_em + pos_mat\n",
    "\n",
    "        text_encoder = TextEncoder()\n",
    "\n",
    "        image_vec, question_vec = model(img_pass, qs_em)\n",
    "        _, ans_vec = model(img_pass, ans_em)\n",
    "\n",
    "        add_vec = image_vec + question_vec\n",
    "        dot_pro = torch.matmul(add_vec, ans_vec.T)\n",
    "\n",
    "        print(dot_pro.shape)\n",
    "        break\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 196, 16])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_em.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 3, 224, 224])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 196, 16])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "img_em = layer(imgs)\n",
    "img_em = img_em.permute(0, 2, 3, 1)\n",
    "img_em = img_em.view(batch_size, 196, 16)\n",
    "\n",
    "hoo = ImageEncoder()\n",
    "img_em = hoo(img_em)\n",
    "img_em.shape\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 7, 16])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_encoder = TextEncoder()\n",
    "encoded_q = text_encoder(qs)\n",
    "encoded_q.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "linear(): argument 'input' (position 1) must be Tensor, not tuple",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[76], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m encoded_a \u001b[38;5;241m=\u001b[39m \u001b[43mtext_encoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mans\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m encoded_a\u001b[38;5;241m.\u001b[39mshape\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[16], line 23\u001b[0m, in \u001b[0;36mTextEncoder.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 23\u001b[0m     Q \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mw_q\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m     K \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mw_k(x)\n\u001b[1;32m     25\u001b[0m     V \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mw_k(x)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py:125\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: linear(): argument 'input' (position 1) must be Tensor, not tuple"
     ]
    }
   ],
   "source": [
    "encoded_a = text_encoder(ans)\n",
    "encoded_a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "only one element tensors can be converted to Python scalars",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[66], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquestion_embeddings\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mshape\n",
      "\u001b[0;31mValueError\u001b[0m: only one element tensors can be converted to Python scalars"
     ]
    }
   ],
   "source": [
    "torch.tensor(question_embeddings).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 16])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_embeddings = embedding_gen(\"Joy Maa!\")\n",
    "pe = positional_encodings(vocab_size, embedding_dim)\n",
    "\n",
    "y = input_embeddings + pe\n",
    "\n",
    "text_encoder = TextEncoder()\n",
    "y = y.unsqueeze(0)\n",
    "encoded_text = text_encoder(y)\n",
    "encoded_text.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
